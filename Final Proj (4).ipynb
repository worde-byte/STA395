{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import json\n",
    "my_img = io.imread(r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\images\\ffba62c94141.jpg')\n",
    "io.imshow(my_img)\n",
    "io.show()\n",
    "j = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\annotations\\ffba62c94141.json'\n",
    "f = open(j)\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24909da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd0f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\images'\n",
    "json_path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\annotations'\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "bsize=256\n",
    "\n",
    "img_names = os.listdir(path)\n",
    "#json_names = os.listdir(json_path)\n",
    "i=0\n",
    "#ADD TRAIN TEST SPLIT HERE TO IMG_NAMES\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(img_names, test_size=0.1, random_state=5)\n",
    "\n",
    "images = np.empty(shape = (bsize, 3, 256, 256))\n",
    "labels = np.chararray(bsize, itemsize=20)\n",
    "for idx, name in enumerate(img_names):\n",
    "    if (i==bsize):\n",
    "        break\n",
    "    img_name = path + '\\\\' + name\n",
    "    json_name = json_path + '\\\\' + name\n",
    "    json_name = json_name.replace(json_name[len(json_name) - 3:], 'json')\n",
    "    # Use you favourite library to load the image\n",
    "    image = plt.imread(img_name)\n",
    "    image = image.copy()\n",
    "    image = torch.from_numpy(image)\n",
    "    image = torch.unsqueeze(image, dim=0)\n",
    "    image = torch.movedim(image, source=3, destination=1)\n",
    "    image = functional.interpolate(image, size = (256,256))\n",
    "    \n",
    "    f = open(json_name)\n",
    "    data = json.load(f)\n",
    "    t = data['chart-type']\n",
    "    images[idx] = image\n",
    "    labels[idx] = t\n",
    "    f.close()\n",
    "    \n",
    "    #image_resized = functional.interpolate(image, size = (128,128))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d79e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc9b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_img=images[45]\n",
    "io.imshow(my_img)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce7bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "efnet_weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "efnet_model = torchvision.models.efficientnet_b0(weights = efnet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through each parameter and set `requires_grad` to false\n",
    "for param in efnet_model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace the \"classifier\" layer with one for our application\n",
    "efnet_model.classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features=1280, out_features=4, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4619c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas import get_dummies\n",
    "\n",
    "train_y=labels\n",
    "train_X=images\n",
    "\n",
    "encode_list = [b'vertical_bar',b'scatter',b'dot',b'line']\n",
    "# Create an instance of the OneHotEncoder class and fit it on the data\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder.fit(train_y.reshape(-1, 1))\n",
    "\n",
    "# Transform the data using the fitted encoder\n",
    "encoded_data = encoder.transform(train_y.reshape(-1, 1))\n",
    "\n",
    "# Map the encoded data to the desired format\n",
    "train_y = [encoder.categories_[0].tolist().index(category) for category in encoder.inverse_transform(encoded_data).flatten()]\n",
    "\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ce064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "y_tensor = torch.tensor(train_y)\n",
    "\n",
    "### Convert to numpy array then reshape to 900 by 28 by 28\n",
    "mnist_unflattened = train_X\n",
    "mnist_unflattened = mnist_unflattened.reshape(256, 3, 256, 256)\n",
    "\n",
    "## Convert to tensor\n",
    "mnist_tensor = torch.from_numpy(mnist_unflattened)\n",
    "mnist_tensor =  torch.unsqueeze(mnist_tensor, dim=1)\n",
    "\n",
    "## Transform to proper input shape\n",
    "new_mnist_tensors = mnist_tensor.expand(-1, -1, -1, -1, -1)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(new_mnist_tensors.type(torch.FloatTensor), y_tensor.type(torch.LongTensor)), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd549ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparms\n",
    "epochs = 100\n",
    "lrate = 0.1\n",
    "\n",
    "## Cost Function\n",
    "from torch import nn\n",
    "cost_fn = nn.NLLLoss()\n",
    "\n",
    "## Network model\n",
    "torch.manual_seed(7) # For reproduction purposes (should be minor since only the last layers are randomly intialized)\n",
    "net = efnet_model\n",
    "\n",
    "## Optimizer (using ADAM, a more flexible algorithm than SGD this time)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lrate)\n",
    "\n",
    "## Initial values for cost tracking\n",
    "track_cost = np.zeros(epochs)\n",
    "cur_cost = 0.0\n",
    "\n",
    "## Loop through the data\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    cur_cost = 0.0\n",
    "    correct = 0.0\n",
    "    \n",
    "    ## train_loader is iterable and numbers knows the batch\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        ## The input tensor and labels tensor for the current batch\n",
    "        inputs, labels = data\n",
    "        ## Clear the gradient from the previous batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## Provide the input tensor into the network to get outputs\n",
    "        inputs = inputs.reshape((32, 3, 256, 256))\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        ## Calculate the cost for the current batch\n",
    "        cost = cost_fn(outputs.log_softmax(dim=1), labels)\n",
    "        \n",
    "        ## Calculate the gradient\n",
    "        cost.backward()\n",
    "        \n",
    "        ## Update the model parameters using the gradient\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## Track the current cost (accumulating across batches)\n",
    "        cur_cost += cost.item()\n",
    "    \n",
    "    ## Store the accumulated cost at each epoch\n",
    "    track_cost[epoch] = cur_cost\n",
    "    print(f\"Epoch: {epoch} Cost: {cur_cost}\") ## Uncomment this if you want printed updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25777f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d4ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169dd465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb958b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd043056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05682f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49c070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\images'\n",
    "json_path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\annotations'\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas import get_dummies\n",
    "\n",
    "bsize=256\n",
    "\n",
    "img_names = os.listdir(path)\n",
    "#img_name = path + '\\\\' + name\n",
    "#json_names = os.listdir(json_path)\n",
    "i=0\n",
    "#ADD TRAIN TEST SPLIT HERE TO IMG_NAMES\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(img_names, test_size=0.99, random_state=5)\n",
    "\n",
    "images = np.empty(shape = (bsize, 3, 256, 256))\n",
    "labels = np.chararray(bsize, itemsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3e3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.copy()\n",
    "train_X = train.copy()\n",
    "for i in range(len(train)):\n",
    "    train_X[i] = path + '\\\\' + img_names[i]\n",
    "    train_y[i] = json_path + '\\\\' + img_names[i]\n",
    "    train_y[i] = train_y[i].replace(train_y[i][len(train_y[i]) - 3:], 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d10c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f95a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a180ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index])\n",
    "        f = open(self.label_paths[index])\n",
    "        data = json.load(f)\n",
    "        t = data['chart-type']\n",
    "        #print(t)\n",
    "        if (t=='scatter'):\n",
    "            label = 0\n",
    "        elif (t=='vertical_bar'):\n",
    "            label = 1\n",
    "        elif (t=='dot'):\n",
    "            label = 2\n",
    "        else:\n",
    "            label = 3\n",
    "        f.close()\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            #label = self.transform(label)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# Define the transform to resize and normalize the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create a dataset from the image and label file paths\n",
    "dataset = MyDataset(train_X, train_y, transform=transform)\n",
    "\n",
    "# Create a dataloader to load the data in batches\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843399b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "efnet_weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "efnet_model = torchvision.models.efficientnet_b0(weights = efnet_weights)\n",
    "## Loop through each parameter and set `requires_grad` to false\n",
    "for param in efnet_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "## Replace the \"classifier\" layer with one for our application\n",
    "efnet_model.classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features=1280, out_features=4, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b159ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Cost: 12.282479166984558\n",
      "Epoch: 1 Cost: 2.9375903010368347\n",
      "Epoch: 2 Cost: 2.6073168516159058\n",
      "Epoch: 3 Cost: 0.5780415870249271\n",
      "Epoch: 4 Cost: 0.7651243954896927\n",
      "Epoch: 5 Cost: 0.6312493895529769\n",
      "Epoch: 6 Cost: 0.715614378452301\n",
      "Epoch: 7 Cost: 0.4981958493590355\n",
      "Epoch: 8 Cost: 0.23268637154251337\n",
      "Epoch: 9 Cost: 0.1204118556343019\n"
     ]
    }
   ],
   "source": [
    "#encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Train the neural network on the data using batches\n",
    "from torch import nn\n",
    "epochs = 10\n",
    "lrate = 0.1\n",
    "cost_fn = nn.NLLLoss()\n",
    "net = efnet_model\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lrate)\n",
    "track_cost = np.zeros(epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    cur_cost = 0.0\n",
    "    correct = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.reshape(inputs.size())\n",
    "        outputs = net(inputs)\n",
    "        #print(labels)\n",
    "        \n",
    "        cost = cost_fn(outputs.log_softmax(dim=1), labels)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        cur_cost += cost.item()\n",
    "        \n",
    "    track_cost[epoch] = cur_cost\n",
    "    print(f\"Epoch: {epoch} Cost: {cur_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16fdb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD TEST CODE TO MAKE SURE IT WORKS\n",
    "test_y = test.copy()\n",
    "test_X = test.copy()\n",
    "i=0\n",
    "for i in range(len(test)):\n",
    "    test_X[i] = path + '\\\\' + img_names[i]\n",
    "    test_y[i] = json_path + '\\\\' + img_names[i]\n",
    "    test_y[i] = test_y[i].replace(test_y[i][len(test_y[i]) - 3:], 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e436db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(test_X, test_y, transform=transform)\n",
    "\n",
    "# Create a dataloader to load the data in batches\n",
    "batch_size = 256\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc975a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model to evaluation mode\n",
    "#net.eval()\n",
    "\n",
    "# iterate through test data and generate predictions\n",
    "#with torch.no_grad():\n",
    "    #predicted = []\n",
    "    #for data in test_loader:\n",
    "        #inputs, _ = data\n",
    "        #inputs = inputs.reshape(inputs.size())\n",
    "        #outputs = net(inputs)\n",
    "        #_, pred = torch.max(outputs.data, 1)\n",
    "        #predicted.append(pred.numpy())\n",
    "\n",
    "# convert predicted labels to numpy array\n",
    "#predicted = np.concatenate(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af597ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1791360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2, 3, 3, 0, 3, 1, 3, 3, 3, 2, 1, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 3,\n",
      "        3, 2, 0, 3, 3, 2, 1, 2, 0, 0, 2, 1, 1, 1, 1, 3, 3, 1, 1, 0, 1, 1, 3, 0,\n",
      "        1, 1, 0, 3, 1, 1, 3, 0, 1, 3, 2, 3, 1, 1, 3, 0, 3, 1, 1, 3, 0, 1, 1, 3,\n",
      "        1, 3, 1, 3, 1, 1, 1, 2, 2, 3, 0, 3, 3, 3, 3, 1, 1, 3, 3, 1, 3, 1, 3, 3,\n",
      "        3, 1, 1, 1, 3, 1, 2, 1, 1, 1, 0, 2, 3, 3, 3, 0, 3, 1, 1, 3, 1, 0, 1, 1,\n",
      "        3, 1, 0, 1, 0, 0, 0, 0, 3, 3, 1, 0, 1, 1, 3, 0, 1, 0, 1, 1, 3, 2, 3, 3,\n",
      "        3, 0, 2, 3, 3, 3, 3, 3, 3, 0, 0, 1, 0, 1, 3, 3, 1, 1, 1, 3, 3, 3, 3, 1,\n",
      "        3, 3, 3, 3, 3, 0, 1, 1, 1, 3, 1, 0, 3, 3, 1, 3, 3, 3, 3, 0, 3, 3, 0, 2,\n",
      "        1, 3, 3, 1, 0, 0, 1, 1, 1, 3, 0, 3, 3, 3, 1, 3, 1, 0, 0, 0, 1, 3, 1, 3,\n",
      "        0, 1, 3, 0, 3, 1, 3, 2, 2, 0, 3, 0, 3, 2, 1, 2, 3, 1, 3, 3, 0, 0, 1, 0,\n",
      "        0, 1, 2, 3, 3, 1, 1, 3, 3, 2, 1, 2, 3, 3, 2, 0])\n",
      "tensor([1, 1, 2, 3, 3, 0, 3, 1, 3, 3, 3, 2, 1, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 3,\n",
      "        3, 2, 0, 3, 3, 2, 1, 2, 0, 0, 2, 1, 1, 1, 1, 3, 3, 1, 1, 0, 1, 1, 3, 0,\n",
      "        1, 1, 0, 3, 1, 1, 3, 0, 1, 3, 2, 3, 1, 1, 3, 0, 3, 1, 1, 3, 0, 1, 1, 3,\n",
      "        1, 3, 1, 3, 1, 1, 1, 2, 2, 3, 0, 3, 3, 3, 1, 1, 1, 3, 3, 1, 1, 1, 3, 3,\n",
      "        3, 1, 1, 1, 3, 1, 2, 1, 1, 1, 0, 2, 3, 3, 3, 0, 3, 1, 1, 3, 1, 0, 1, 1,\n",
      "        3, 1, 0, 1, 0, 0, 0, 0, 3, 3, 1, 0, 1, 1, 3, 0, 1, 0, 1, 1, 3, 2, 3, 3,\n",
      "        3, 0, 2, 3, 3, 3, 3, 3, 3, 0, 0, 1, 0, 1, 3, 3, 1, 1, 1, 3, 3, 3, 3, 1,\n",
      "        3, 3, 3, 3, 3, 0, 1, 1, 1, 3, 1, 0, 3, 3, 1, 3, 3, 3, 3, 0, 3, 3, 0, 2,\n",
      "        1, 3, 3, 1, 0, 0, 1, 1, 1, 3, 0, 3, 3, 3, 1, 3, 1, 0, 0, 0, 1, 3, 1, 3,\n",
      "        0, 1, 3, 0, 3, 1, 3, 2, 3, 0, 3, 0, 3, 1, 1, 2, 3, 1, 3, 3, 3, 0, 1, 0,\n",
      "        0, 1, 2, 3, 3, 1, 1, 3, 3, 2, 1, 2, 3, 3, 2, 0])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16532\\964120950.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "# set model to evaluation mode\n",
    "net.eval()\n",
    "\n",
    "# iterate through test data and generate predictions\n",
    "with torch.no_grad():\n",
    "    predicted = []\n",
    "    actual = []\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        #inputs = inputs.reshape(inputs.size())\n",
    "        outputs = net(inputs)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        predicted.append(pred.numpy())\n",
    "        actual.append(labels.numpy())\n",
    "        print(pred)\n",
    "        print(labels)\n",
    "        if (pred != labels):\n",
    "            print(inputs)\n",
    "\n",
    "# concatenate predicted and actual labels\n",
    "predicted = np.concatenate(predicted)\n",
    "actual = np.concatenate(actual)\n",
    "\n",
    "# compute accuracy\n",
    "accuracy = np.mean(predicted == actual)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9b10c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = json_path + '\\\\' + '18a1ca02e41e.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c722b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\annotations\\ffba62c94141.json'\n",
    "f = open(j)\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b218770a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'generated',\n",
       " 'chart-type': 'scatter',\n",
       " 'plot-bb': {'height': 182, 'width': 413, 'x0': 72, 'y0': 64},\n",
       " 'text': [{'id': 0,\n",
       "   'polygon': {'x0': 58,\n",
       "    'x1': 442,\n",
       "    'x2': 442,\n",
       "    'x3': 58,\n",
       "    'y0': 6,\n",
       "    'y1': 6,\n",
       "    'y2': 47,\n",
       "    'y3': 47},\n",
       "   'text': 'TOTAL ARMY PERSONAL IN MIDDLE EAST & NORTH AFRICA (EXCLUDING HIGH INCOME)',\n",
       "   'role': 'chart_title'},\n",
       "  {'id': 1,\n",
       "   'polygon': {'x0': 7,\n",
       "    'x1': 20,\n",
       "    'x2': 20,\n",
       "    'x3': 7,\n",
       "    'y0': 72,\n",
       "    'y1': 72,\n",
       "    'y2': 163,\n",
       "    'y3': 163},\n",
       "   'text': 'Soldiers (*10000)',\n",
       "   'role': 'axis_title'},\n",
       "  {'id': 2,\n",
       "   'polygon': {'x0': 264,\n",
       "    'x1': 289,\n",
       "    'x2': 289,\n",
       "    'x3': 264,\n",
       "    'y0': 274,\n",
       "    'y1': 274,\n",
       "    'y2': 285,\n",
       "    'y3': 285},\n",
       "   'text': 'Year',\n",
       "   'role': 'axis_title'},\n",
       "  {'id': 3,\n",
       "   'polygon': {'x0': 26,\n",
       "    'x1': 63,\n",
       "    'x2': 63,\n",
       "    'x3': 26,\n",
       "    'y0': 58,\n",
       "    'y1': 58,\n",
       "    'y2': 69,\n",
       "    'y3': 69},\n",
       "   'text': '400.00',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 4,\n",
       "   'polygon': {'x0': 27,\n",
       "    'x1': 63,\n",
       "    'x2': 63,\n",
       "    'x3': 27,\n",
       "    'y0': 81,\n",
       "    'y1': 81,\n",
       "    'y2': 92,\n",
       "    'y3': 92},\n",
       "   'text': '350.00',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 5,\n",
       "   'polygon': {'x0': 27,\n",
       "    'x1': 63,\n",
       "    'x2': 63,\n",
       "    'x3': 27,\n",
       "    'y0': 104,\n",
       "    'y1': 104,\n",
       "    'y2': 115,\n",
       "    'y3': 115},\n",
       "   'text': '300.00',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 6,\n",
       "   'polygon': {'x0': 26,\n",
       "    'x1': 63,\n",
       "    'x2': 63,\n",
       "    'x3': 26,\n",
       "    'y0': 126,\n",
       "    'y1': 126,\n",
       "    'y2': 137,\n",
       "    'y3': 137},\n",
       "   'text': '250.00',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 7,\n",
       "   'polygon': {'x0': 27,\n",
       "    'x1': 63,\n",
       "    'x2': 63,\n",
       "    'x3': 27,\n",
       "    'y0': 149,\n",
       "    'y1': 149,\n",
       "    'y2': 160,\n",
       "    'y3': 160},\n",
       "   'text': '200.00',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 8,\n",
       "   'polygon': {'x0': 27,\n",
       "    'x1': 63,\n",
       "    'x2': 63,\n",
       "    'x3': 27,\n",
       "    'y0': 172,\n",
       "    'y1': 172,\n",
       "    'y2': 183,\n",
       "    'y3': 183},\n",
       "   'text': '150.00',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 9,\n",
       "   'polygon': {'x0': 27,\n",
       "    'x1': 63,\n",
       "    'x2': 63,\n",
       "    'x3': 27,\n",
       "    'y0': 194,\n",
       "    'y1': 194,\n",
       "    'y2': 205,\n",
       "    'y3': 205},\n",
       "   'text': '100.00',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 10,\n",
       "   'polygon': {'x0': 32,\n",
       "    'x1': 61,\n",
       "    'x2': 61,\n",
       "    'x3': 32,\n",
       "    'y0': 216,\n",
       "    'y1': 216,\n",
       "    'y2': 228,\n",
       "    'y3': 228},\n",
       "   'text': '50.00',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 11,\n",
       "   'polygon': {'x0': 38,\n",
       "    'x1': 63,\n",
       "    'x2': 63,\n",
       "    'x3': 38,\n",
       "    'y0': 239,\n",
       "    'y1': 239,\n",
       "    'y2': 250,\n",
       "    'y3': 250},\n",
       "   'text': '0.00',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 12,\n",
       "   'polygon': {'x0': 59,\n",
       "    'x1': 86,\n",
       "    'x2': 86,\n",
       "    'x3': 59,\n",
       "    'y0': 255,\n",
       "    'y1': 255,\n",
       "    'y2': 266,\n",
       "    'y3': 266},\n",
       "   'text': '1980',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 13,\n",
       "   'polygon': {'x0': 110,\n",
       "    'x1': 137,\n",
       "    'x2': 137,\n",
       "    'x3': 110,\n",
       "    'y0': 255,\n",
       "    'y1': 255,\n",
       "    'y2': 266,\n",
       "    'y3': 266},\n",
       "   'text': '1985',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 14,\n",
       "   'polygon': {'x0': 162,\n",
       "    'x1': 189,\n",
       "    'x2': 189,\n",
       "    'x3': 162,\n",
       "    'y0': 255,\n",
       "    'y1': 255,\n",
       "    'y2': 266,\n",
       "    'y3': 266},\n",
       "   'text': '1990',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 15,\n",
       "   'polygon': {'x0': 213,\n",
       "    'x1': 240,\n",
       "    'x2': 240,\n",
       "    'x3': 213,\n",
       "    'y0': 255,\n",
       "    'y1': 255,\n",
       "    'y2': 266,\n",
       "    'y3': 266},\n",
       "   'text': '1995',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 16,\n",
       "   'polygon': {'x0': 264,\n",
       "    'x1': 291,\n",
       "    'x2': 291,\n",
       "    'x3': 264,\n",
       "    'y0': 255,\n",
       "    'y1': 255,\n",
       "    'y2': 266,\n",
       "    'y3': 266},\n",
       "   'text': '2000',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 17,\n",
       "   'polygon': {'x0': 315,\n",
       "    'x1': 342,\n",
       "    'x2': 342,\n",
       "    'x3': 315,\n",
       "    'y0': 255,\n",
       "    'y1': 255,\n",
       "    'y2': 266,\n",
       "    'y3': 266},\n",
       "   'text': '2005',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 18,\n",
       "   'polygon': {'x0': 369,\n",
       "    'x1': 394,\n",
       "    'x2': 394,\n",
       "    'x3': 369,\n",
       "    'y0': 255,\n",
       "    'y1': 255,\n",
       "    'y2': 266,\n",
       "    'y3': 266},\n",
       "   'text': '2010',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 19,\n",
       "   'polygon': {'x0': 419,\n",
       "    'x1': 445,\n",
       "    'x2': 445,\n",
       "    'x3': 419,\n",
       "    'y0': 255,\n",
       "    'y1': 255,\n",
       "    'y2': 266,\n",
       "    'y3': 266},\n",
       "   'text': '2015',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 20,\n",
       "   'polygon': {'x0': 469,\n",
       "    'x1': 496,\n",
       "    'x2': 496,\n",
       "    'x3': 469,\n",
       "    'y0': 255,\n",
       "    'y1': 255,\n",
       "    'y2': 266,\n",
       "    'y3': 266},\n",
       "   'text': '2020',\n",
       "   'role': 'tick_label'}],\n",
       " 'axes': {'x-axis': {'ticks': [{'id': 12, 'tick_pt': {'x': 72, 'y': 246}},\n",
       "    {'id': 13, 'tick_pt': {'x': 123, 'y': 246}},\n",
       "    {'id': 14, 'tick_pt': {'x': 175, 'y': 246}},\n",
       "    {'id': 15, 'tick_pt': {'x': 226, 'y': 246}},\n",
       "    {'id': 16, 'tick_pt': {'x': 278, 'y': 246}},\n",
       "    {'id': 17, 'tick_pt': {'x': 329, 'y': 246}},\n",
       "    {'id': 18, 'tick_pt': {'x': 380, 'y': 246}},\n",
       "    {'id': 19, 'tick_pt': {'x': 432, 'y': 246}},\n",
       "    {'id': 20, 'tick_pt': {'x': 483, 'y': 246}}],\n",
       "   'tick-type': 'markers',\n",
       "   'values-type': 'numerical'},\n",
       "  'y-axis': {'ticks': [{'id': 3, 'tick_pt': {'x': 72, 'y': 64}},\n",
       "    {'id': 4, 'tick_pt': {'x': 72, 'y': 87}},\n",
       "    {'id': 5, 'tick_pt': {'x': 72, 'y': 109}},\n",
       "    {'id': 6, 'tick_pt': {'x': 72, 'y': 132}},\n",
       "    {'id': 7, 'tick_pt': {'x': 72, 'y': 155}},\n",
       "    {'id': 8, 'tick_pt': {'x': 72, 'y': 178}},\n",
       "    {'id': 9, 'tick_pt': {'x': 72, 'y': 200}},\n",
       "    {'id': 10, 'tick_pt': {'x': 72, 'y': 223}},\n",
       "    {'id': 11, 'tick_pt': {'x': 72, 'y': 246}}],\n",
       "   'tick-type': 'markers',\n",
       "   'values-type': 'numerical'}},\n",
       " 'visual-elements': {'bars': [],\n",
       "  'boxplots': [],\n",
       "  'dot points': [],\n",
       "  'lines': [],\n",
       "  'scatter points': [[{'x': 124.0, 'y': 107.69999999999999},\n",
       "    {'x': 194.66666666666666, 'y': 135.69999999999996},\n",
       "    {'x': 216.0, 'y': 137.69999999999996},\n",
       "    {'x': 236.66666666666666, 'y': 93.69999999999999},\n",
       "    {'x': 256.6666666666667, 'y': 91.69999999999999},\n",
       "    {'x': 287.3333333333333, 'y': 98.36666666666662},\n",
       "    {'x': 318.0, 'y': 115.0333333333333},\n",
       "    {'x': 348.6666666666667, 'y': 97.0333333333333},\n",
       "    {'x': 380.0, 'y': 81.69999999999999},\n",
       "    {'x': 400.0, 'y': 91.0333333333333},\n",
       "    {'x': 420.6666666666667, 'y': 122.36666666666663},\n",
       "    {'x': 442.0, 'y': 120.36666666666663},\n",
       "    {'x': 463.3333333333333, 'y': 113.69999999999999}]]},\n",
       " 'data-series': [{'x': 1985.0567260940034, 'y': 303.93845026561644},\n",
       "  {'x': 1991.92868719611, 'y': 242.38871588202977},\n",
       "  {'x': 1994.0032414910859, 'y': 237.99230628320217},\n",
       "  {'x': 1996.0129659643435, 'y': 334.7133174574098},\n",
       "  {'x': 1997.9578606158834, 'y': 339.10972705623743},\n",
       "  {'x': 2000.9400324149108, 'y': 324.45502839347876},\n",
       "  {'x': 2003.9222042139384, 'y': 287.81828173658187},\n",
       "  {'x': 2006.904376012966, 'y': 327.3859681260305},\n",
       "  {'x': 2009.9513776337114, 'y': 361.09177505037553},\n",
       "  {'x': 2011.8962722852511, 'y': 340.5751969225133},\n",
       "  {'x': 2013.905996758509, 'y': 271.6981132075473},\n",
       "  {'x': 2015.9805510534845, 'y': 276.09452280637487},\n",
       "  {'x': 2018.0551053484603, 'y': 290.7492214691336}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5262c964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 1985.0567260940034, 'y': 303.93845026561644},\n",
       " {'x': 1991.92868719611, 'y': 242.38871588202977},\n",
       " {'x': 1994.0032414910859, 'y': 237.99230628320217},\n",
       " {'x': 1996.0129659643435, 'y': 334.7133174574098},\n",
       " {'x': 1997.9578606158834, 'y': 339.10972705623743},\n",
       " {'x': 2000.9400324149108, 'y': 324.45502839347876},\n",
       " {'x': 2003.9222042139384, 'y': 287.81828173658187},\n",
       " {'x': 2006.904376012966, 'y': 327.3859681260305},\n",
       " {'x': 2009.9513776337114, 'y': 361.09177505037553},\n",
       " {'x': 2011.8962722852511, 'y': 340.5751969225133},\n",
       " {'x': 2013.905996758509, 'y': 271.6981132075473},\n",
       " {'x': 2015.9805510534845, 'y': 276.09452280637487},\n",
       " {'x': 2018.0551053484603, 'y': 290.7492214691336}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data-series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74c1fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6251ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\annotations\\ffbe953e00a1.json'\n",
    "f = open(j)\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e1ce31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'generated',\n",
       " 'chart-type': 'vertical_bar',\n",
       " 'plot-bb': {'height': 180, 'width': 426, 'x0': 63, 'y0': 27},\n",
       " 'text': [{'id': 0,\n",
       "   'polygon': {'x0': 100,\n",
       "    'x1': 402,\n",
       "    'x2': 402,\n",
       "    'x3': 100,\n",
       "    'y0': 4,\n",
       "    'y1': 4,\n",
       "    'y2': 19,\n",
       "    'y3': 19},\n",
       "   'text': 'CO2 Emisions by burning coal for the year 2016',\n",
       "   'role': 'chart_title'},\n",
       "  {'id': 1,\n",
       "   'polygon': {'x0': 253,\n",
       "    'x1': 298,\n",
       "    'x2': 298,\n",
       "    'x3': 253,\n",
       "    'y0': 265,\n",
       "    'y1': 265,\n",
       "    'y2': 277,\n",
       "    'y3': 277},\n",
       "   'text': 'Country',\n",
       "   'role': 'axis_title'},\n",
       "  {'id': 2,\n",
       "   'polygon': {'x0': 3,\n",
       "    'x1': 16,\n",
       "    'x2': 16,\n",
       "    'x3': 3,\n",
       "    'y0': 39,\n",
       "    'y1': 39,\n",
       "    'y2': 195,\n",
       "    'y3': 195},\n",
       "   'text': 'Total CO2 Emissions (*10000)',\n",
       "   'role': 'axis_title'},\n",
       "  {'id': 3,\n",
       "   'polygon': {'x0': 18,\n",
       "    'x1': 55,\n",
       "    'x2': 55,\n",
       "    'x3': 18,\n",
       "    'y0': 21,\n",
       "    'y1': 21,\n",
       "    'y2': 33,\n",
       "    'y3': 33},\n",
       "   'text': '160000',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 4,\n",
       "   'polygon': {'x0': 18,\n",
       "    'x1': 55,\n",
       "    'x2': 55,\n",
       "    'x3': 18,\n",
       "    'y0': 43,\n",
       "    'y1': 43,\n",
       "    'y2': 55,\n",
       "    'y3': 55},\n",
       "   'text': '140000',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 5,\n",
       "   'polygon': {'x0': 19,\n",
       "    'x1': 55,\n",
       "    'x2': 55,\n",
       "    'x3': 19,\n",
       "    'y0': 66,\n",
       "    'y1': 66,\n",
       "    'y2': 77,\n",
       "    'y3': 77},\n",
       "   'text': '120000',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 6,\n",
       "   'polygon': {'x0': 19,\n",
       "    'x1': 55,\n",
       "    'x2': 55,\n",
       "    'x3': 19,\n",
       "    'y0': 88,\n",
       "    'y1': 88,\n",
       "    'y2': 100,\n",
       "    'y3': 100},\n",
       "   'text': '100000',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 7,\n",
       "   'polygon': {'x0': 22,\n",
       "    'x1': 55,\n",
       "    'x2': 55,\n",
       "    'x3': 22,\n",
       "    'y0': 111,\n",
       "    'y1': 111,\n",
       "    'y2': 122,\n",
       "    'y3': 122},\n",
       "   'text': '80000',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 8,\n",
       "   'polygon': {'x0': 22,\n",
       "    'x1': 55,\n",
       "    'x2': 55,\n",
       "    'x3': 22,\n",
       "    'y0': 133,\n",
       "    'y1': 133,\n",
       "    'y2': 145,\n",
       "    'y3': 145},\n",
       "   'text': '60000',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 9,\n",
       "   'polygon': {'x0': 22,\n",
       "    'x1': 55,\n",
       "    'x2': 55,\n",
       "    'x3': 22,\n",
       "    'y0': 155,\n",
       "    'y1': 155,\n",
       "    'y2': 166,\n",
       "    'y3': 166},\n",
       "   'text': '40000',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 10,\n",
       "   'polygon': {'x0': 22,\n",
       "    'x1': 55,\n",
       "    'x2': 55,\n",
       "    'x3': 22,\n",
       "    'y0': 177,\n",
       "    'y1': 177,\n",
       "    'y2': 189,\n",
       "    'y3': 189},\n",
       "   'text': '20000',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 11,\n",
       "   'polygon': {'x0': 46,\n",
       "    'x1': 55,\n",
       "    'x2': 55,\n",
       "    'x3': 46,\n",
       "    'y0': 200,\n",
       "    'y1': 200,\n",
       "    'y2': 211,\n",
       "    'y3': 211},\n",
       "   'text': '0',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 12,\n",
       "   'polygon': {'x0': 39,\n",
       "    'x1': 73,\n",
       "    'x2': 81,\n",
       "    'x3': 47,\n",
       "    'y0': 246,\n",
       "    'y1': 211,\n",
       "    'y2': 220,\n",
       "    'y3': 254},\n",
       "   'text': 'Sri Lanka',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 13,\n",
       "   'polygon': {'x0': 72,\n",
       "    'x1': 101,\n",
       "    'x2': 110,\n",
       "    'x3': 81,\n",
       "    'y0': 241,\n",
       "    'y1': 211,\n",
       "    'y2': 220,\n",
       "    'y3': 249},\n",
       "   'text': 'Sweden',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 14,\n",
       "   'polygon': {'x0': 88,\n",
       "    'x1': 130,\n",
       "    'x2': 138,\n",
       "    'x3': 97,\n",
       "    'y0': 253,\n",
       "    'y1': 212,\n",
       "    'y2': 220,\n",
       "    'y3': 261},\n",
       "   'text': 'Switzerland',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 15,\n",
       "   'polygon': {'x0': 139,\n",
       "    'x1': 159,\n",
       "    'x2': 168,\n",
       "    'x3': 148,\n",
       "    'y0': 230,\n",
       "    'y1': 212,\n",
       "    'y2': 222,\n",
       "    'y3': 240},\n",
       "   'text': 'Syria',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 16,\n",
       "   'polygon': {'x0': 160,\n",
       "    'x1': 187,\n",
       "    'x2': 195,\n",
       "    'x3': 168,\n",
       "    'y0': 239,\n",
       "    'y1': 212,\n",
       "    'y2': 220,\n",
       "    'y3': 247},\n",
       "   'text': 'Taiwan',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 17,\n",
       "   'polygon': {'x0': 180,\n",
       "    'x1': 215,\n",
       "    'x2': 224,\n",
       "    'x3': 190,\n",
       "    'y0': 246,\n",
       "    'y1': 212,\n",
       "    'y2': 222,\n",
       "    'y3': 256},\n",
       "   'text': 'Tajikistan',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 18,\n",
       "   'polygon': {'x0': 209,\n",
       "    'x1': 243,\n",
       "    'x2': 251,\n",
       "    'x3': 218,\n",
       "    'y0': 245,\n",
       "    'y1': 211,\n",
       "    'y2': 220,\n",
       "    'y3': 253},\n",
       "   'text': 'Tanzania',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 19,\n",
       "   'polygon': {'x0': 240,\n",
       "    'x1': 272,\n",
       "    'x2': 280,\n",
       "    'x3': 249,\n",
       "    'y0': 243,\n",
       "    'y1': 212,\n",
       "    'y2': 220,\n",
       "    'y3': 251},\n",
       "   'text': 'Thailand',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 20,\n",
       "   'polygon': {'x0': 260,\n",
       "    'x1': 300,\n",
       "    'x2': 308,\n",
       "    'x3': 269,\n",
       "    'y0': 251,\n",
       "    'y1': 212,\n",
       "    'y2': 220,\n",
       "    'y3': 259},\n",
       "   'text': 'Uzbekistan',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 21,\n",
       "   'polygon': {'x0': 290,\n",
       "    'x1': 328,\n",
       "    'x2': 336,\n",
       "    'x3': 298,\n",
       "    'y0': 249,\n",
       "    'y1': 212,\n",
       "    'y2': 221,\n",
       "    'y3': 258},\n",
       "   'text': 'Venezuela',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 22,\n",
       "   'polygon': {'x0': 326,\n",
       "    'x1': 359,\n",
       "    'x2': 366,\n",
       "    'x3': 334,\n",
       "    'y0': 241,\n",
       "    'y1': 213,\n",
       "    'y2': 222,\n",
       "    'y3': 250},\n",
       "   'text': 'Vietnam',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 23,\n",
       "   'polygon': {'x0': 363,\n",
       "    'x1': 385,\n",
       "    'x2': 393,\n",
       "    'x3': 371,\n",
       "    'y0': 234,\n",
       "    'y1': 211,\n",
       "    'y2': 220,\n",
       "    'y3': 242},\n",
       "   'text': 'World',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 24,\n",
       "   'polygon': {'x0': 387,\n",
       "    'x1': 413,\n",
       "    'x2': 421,\n",
       "    'x3': 395,\n",
       "    'y0': 238,\n",
       "    'y1': 211,\n",
       "    'y2': 220,\n",
       "    'y3': 246},\n",
       "   'text': 'Yemen',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 25,\n",
       "   'polygon': {'x0': 414,\n",
       "    'x1': 442,\n",
       "    'x2': 450,\n",
       "    'x3': 423,\n",
       "    'y0': 239,\n",
       "    'y1': 212,\n",
       "    'y2': 220,\n",
       "    'y3': 247},\n",
       "   'text': 'Zambia',\n",
       "   'role': 'tick_label'},\n",
       "  {'id': 26,\n",
       "   'polygon': {'x0': 433,\n",
       "    'x1': 470,\n",
       "    'x2': 478,\n",
       "    'x3': 441,\n",
       "    'y0': 249,\n",
       "    'y1': 211,\n",
       "    'y2': 220,\n",
       "    'y3': 257},\n",
       "   'text': 'Zimbabwe',\n",
       "   'role': 'tick_label'}],\n",
       " 'axes': {'x-axis': {'ticks': [{'id': 12, 'tick_pt': {'x': 76, 'y': 208}},\n",
       "    {'id': 13, 'tick_pt': {'x': 105, 'y': 208}},\n",
       "    {'id': 14, 'tick_pt': {'x': 134, 'y': 208}},\n",
       "    {'id': 15, 'tick_pt': {'x': 162, 'y': 208}},\n",
       "    {'id': 16, 'tick_pt': {'x': 190, 'y': 208}},\n",
       "    {'id': 17, 'tick_pt': {'x': 218, 'y': 208}},\n",
       "    {'id': 18, 'tick_pt': {'x': 246, 'y': 208}},\n",
       "    {'id': 19, 'tick_pt': {'x': 275, 'y': 208}},\n",
       "    {'id': 20, 'tick_pt': {'x': 305, 'y': 208}},\n",
       "    {'id': 21, 'tick_pt': {'x': 333, 'y': 208}},\n",
       "    {'id': 22, 'tick_pt': {'x': 360, 'y': 208}},\n",
       "    {'id': 23, 'tick_pt': {'x': 389, 'y': 208}},\n",
       "    {'id': 24, 'tick_pt': {'x': 417, 'y': 208}},\n",
       "    {'id': 25, 'tick_pt': {'x': 446, 'y': 208}},\n",
       "    {'id': 26, 'tick_pt': {'x': 474, 'y': 208}}],\n",
       "   'tick-type': 'markers',\n",
       "   'values-type': 'categorical'},\n",
       "  'y-axis': {'ticks': [{'id': 3, 'tick_pt': {'x': 63, 'y': 27}},\n",
       "    {'id': 4, 'tick_pt': {'x': 63, 'y': 50}},\n",
       "    {'id': 5, 'tick_pt': {'x': 63, 'y': 72}},\n",
       "    {'id': 6, 'tick_pt': {'x': 63, 'y': 95}},\n",
       "    {'id': 7, 'tick_pt': {'x': 63, 'y': 118}},\n",
       "    {'id': 8, 'tick_pt': {'x': 63, 'y': 140}},\n",
       "    {'id': 9, 'tick_pt': {'x': 63, 'y': 163}},\n",
       "    {'id': 10, 'tick_pt': {'x': 63, 'y': 185}},\n",
       "    {'id': 11, 'tick_pt': {'x': 63, 'y': 208}}],\n",
       "   'tick-type': 'markers',\n",
       "   'values-type': 'numerical'}},\n",
       " 'visual-elements': {'bars': [{'height': 40, 'width': 14, 'x0': 69, 'y0': 167},\n",
       "   {'height': 102, 'width': 14, 'x0': 97, 'y0': 105},\n",
       "   {'height': 54, 'width': 14, 'x0': 126, 'y0': 153},\n",
       "   {'height': 31, 'width': 14, 'x0': 154, 'y0': 176},\n",
       "   {'height': 130, 'width': 14, 'x0': 182, 'y0': 77},\n",
       "   {'height': 99, 'width': 14, 'x0': 211, 'y0': 108},\n",
       "   {'height': 77, 'width': 14, 'x0': 239, 'y0': 130},\n",
       "   {'height': 119, 'width': 14, 'x0': 268, 'y0': 88},\n",
       "   {'height': 111, 'width': 14, 'x0': 296, 'y0': 96},\n",
       "   {'height': 59, 'width': 14, 'x0': 324, 'y0': 148},\n",
       "   {'height': 144, 'width': 14, 'x0': 353, 'y0': 63},\n",
       "   {'height': 163, 'width': 14, 'x0': 381, 'y0': 44},\n",
       "   {'height': 110, 'width': 14, 'x0': 410, 'y0': 97},\n",
       "   {'height': 88, 'width': 14, 'x0': 438, 'y0': 119},\n",
       "   {'height': 110, 'width': 14, 'x0': 466, 'y0': 97}],\n",
       "  'boxplots': [],\n",
       "  'dot points': [],\n",
       "  'lines': [],\n",
       "  'scatter points': []},\n",
       " 'data-series': [{'x': 'Sri Lanka', 'y': 35785.58934955088},\n",
       "  {'x': 'Sweden', 'y': 91386.3255454662},\n",
       "  {'x': 'Switzerland', 'y': 48207.03041459579},\n",
       "  {'x': 'Syria', 'y': 28096.125833094513},\n",
       "  {'x': 'Taiwan', 'y': 115637.71048198247},\n",
       "  {'x': 'Tajikistan', 'y': 88428.83957759837},\n",
       "  {'x': 'Tanzania', 'y': 68909.43218967065},\n",
       "  {'x': 'Thailand', 'y': 106173.75538480538},\n",
       "  {'x': 'Uzbekistan', 'y': 99075.78906192258},\n",
       "  {'x': 'Venezuela', 'y': 52939.00796318434},\n",
       "  {'x': 'Vietnam', 'y': 128059.15154702736},\n",
       "  {'x': 'World', 'y': 145212.5701606608},\n",
       "  {'x': 'Yemen', 'y': 98484.291868349},\n",
       "  {'x': 'Zambia', 'y': 78373.38728684772},\n",
       "  {'x': 'Zimbabwe', 'y': 98484.291868349}]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "caea21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b95ba825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 'Sri Lanka', 'y': 35785.58934955088},\n",
       " {'x': 'Sweden', 'y': 91386.3255454662},\n",
       " {'x': 'Switzerland', 'y': 48207.03041459579},\n",
       " {'x': 'Syria', 'y': 28096.125833094513},\n",
       " {'x': 'Taiwan', 'y': 115637.71048198247},\n",
       " {'x': 'Tajikistan', 'y': 88428.83957759837},\n",
       " {'x': 'Tanzania', 'y': 68909.43218967065},\n",
       " {'x': 'Thailand', 'y': 106173.75538480538},\n",
       " {'x': 'Uzbekistan', 'y': 99075.78906192258},\n",
       " {'x': 'Venezuela', 'y': 52939.00796318434},\n",
       " {'x': 'Vietnam', 'y': 128059.15154702736},\n",
       " {'x': 'World', 'y': 145212.5701606608},\n",
       " {'x': 'Yemen', 'y': 98484.291868349},\n",
       " {'x': 'Zambia', 'y': 78373.38728684772},\n",
       " {'x': 'Zimbabwe', 'y': 98484.291868349}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data-series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fb80c147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['data-series'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "958746a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 'Sri Lanka', 'y': 35785.58934955088},\n",
       " {'x': 'Sweden', 'y': 91386.3255454662},\n",
       " {'x': 'Switzerland', 'y': 48207.03041459579},\n",
       " {'x': 'Syria', 'y': 28096.125833094513},\n",
       " {'x': 'Taiwan', 'y': 115637.71048198247},\n",
       " {'x': 'Tajikistan', 'y': 88428.83957759837},\n",
       " {'x': 'Tanzania', 'y': 68909.43218967065},\n",
       " {'x': 'Thailand', 'y': 106173.75538480538},\n",
       " {'x': 'Uzbekistan', 'y': 99075.78906192258},\n",
       " {'x': 'Venezuela', 'y': 52939.00796318434},\n",
       " {'x': 'Vietnam', 'y': 128059.15154702736},\n",
       " {'x': 'World', 'y': 145212.5701606608},\n",
       " {'x': 'Yemen', 'y': 98484.291868349},\n",
       " {'x': 'Zambia', 'y': 78373.38728684772},\n",
       " {'x': 'Zimbabwe', 'y': 98484.291868349}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data-series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d44e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"x,\"\n",
    "for i in range(len(data['data-series'])):\n",
    "    x += str(data['data-series'][i]['x'])\n",
    "    x += \";\"\n",
    "x=x[:-1] + ', ' + data['chart-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03dc29c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x,Sri Lanka;Sweden;Switzerland;Syria;Taiwan;Tajikistan;Tanzania;Thailand;Uzbekistan;Venezuela;Vietnam;World;Yemen;Zambia;Zimbabwe, vertical_bar'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf57b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"y,\"\n",
    "for i in range(len(data['data-series'])):\n",
    "    y += str(data['data-series'][i]['y'])\n",
    "    y += \";\"\n",
    "y=y[:-1] + ', ' + data['chart-type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09c12e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y,35785.58934955088;91386.3255454662;48207.03041459579;28096.125833094513;115637.71048198247;88428.83957759837;68909.43218967065;106173.75538480538;99075.78906192258;52939.00796318434;128059.15154702736;145212.5701606608;98484.291868349;78373.38728684772;98484.291868349, vertical_bar'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13d56afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x,Sri Lanka;Sweden;Switzerland;Syria;Taiwan;Tajikistan;Tanzania;Thailand;Uzbekistan;Venezuela;Vietnam;World;Yemen;Zambia;Zimbabwe, vertical_bar\\ny,35785.58934955088;91386.3255454662;48207.03041459579;28096.125833094513;115637.71048198247;88428.83957759837;68909.43218967065;106173.75538480538;99075.78906192258;52939.00796318434;128059.15154702736;145212.5701606608;98484.291868349;78373.38728684772;98484.291868349, vertical_bar'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = x + \"\\n\" + y\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8875d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'160000'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][3]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b41b0baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "66facc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'polygon': {'x0': 100,\n",
       "   'x1': 402,\n",
       "   'x2': 402,\n",
       "   'x3': 100,\n",
       "   'y0': 4,\n",
       "   'y1': 4,\n",
       "   'y2': 19,\n",
       "   'y3': 19},\n",
       "  'text': 'CO2 Emisions by burning coal for the year 2016',\n",
       "  'role': 'chart_title'},\n",
       " {'id': 1,\n",
       "  'polygon': {'x0': 253,\n",
       "   'x1': 298,\n",
       "   'x2': 298,\n",
       "   'x3': 253,\n",
       "   'y0': 265,\n",
       "   'y1': 265,\n",
       "   'y2': 277,\n",
       "   'y3': 277},\n",
       "  'text': 'Country',\n",
       "  'role': 'axis_title'},\n",
       " {'id': 2,\n",
       "  'polygon': {'x0': 3,\n",
       "   'x1': 16,\n",
       "   'x2': 16,\n",
       "   'x3': 3,\n",
       "   'y0': 39,\n",
       "   'y1': 39,\n",
       "   'y2': 195,\n",
       "   'y3': 195},\n",
       "  'text': 'Total CO2 Emissions (*10000)',\n",
       "  'role': 'axis_title'},\n",
       " {'id': 3,\n",
       "  'polygon': {'x0': 18,\n",
       "   'x1': 55,\n",
       "   'x2': 55,\n",
       "   'x3': 18,\n",
       "   'y0': 21,\n",
       "   'y1': 21,\n",
       "   'y2': 33,\n",
       "   'y3': 33},\n",
       "  'text': '160000',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 4,\n",
       "  'polygon': {'x0': 18,\n",
       "   'x1': 55,\n",
       "   'x2': 55,\n",
       "   'x3': 18,\n",
       "   'y0': 43,\n",
       "   'y1': 43,\n",
       "   'y2': 55,\n",
       "   'y3': 55},\n",
       "  'text': '140000',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 5,\n",
       "  'polygon': {'x0': 19,\n",
       "   'x1': 55,\n",
       "   'x2': 55,\n",
       "   'x3': 19,\n",
       "   'y0': 66,\n",
       "   'y1': 66,\n",
       "   'y2': 77,\n",
       "   'y3': 77},\n",
       "  'text': '120000',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 6,\n",
       "  'polygon': {'x0': 19,\n",
       "   'x1': 55,\n",
       "   'x2': 55,\n",
       "   'x3': 19,\n",
       "   'y0': 88,\n",
       "   'y1': 88,\n",
       "   'y2': 100,\n",
       "   'y3': 100},\n",
       "  'text': '100000',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 7,\n",
       "  'polygon': {'x0': 22,\n",
       "   'x1': 55,\n",
       "   'x2': 55,\n",
       "   'x3': 22,\n",
       "   'y0': 111,\n",
       "   'y1': 111,\n",
       "   'y2': 122,\n",
       "   'y3': 122},\n",
       "  'text': '80000',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 8,\n",
       "  'polygon': {'x0': 22,\n",
       "   'x1': 55,\n",
       "   'x2': 55,\n",
       "   'x3': 22,\n",
       "   'y0': 133,\n",
       "   'y1': 133,\n",
       "   'y2': 145,\n",
       "   'y3': 145},\n",
       "  'text': '60000',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 9,\n",
       "  'polygon': {'x0': 22,\n",
       "   'x1': 55,\n",
       "   'x2': 55,\n",
       "   'x3': 22,\n",
       "   'y0': 155,\n",
       "   'y1': 155,\n",
       "   'y2': 166,\n",
       "   'y3': 166},\n",
       "  'text': '40000',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 10,\n",
       "  'polygon': {'x0': 22,\n",
       "   'x1': 55,\n",
       "   'x2': 55,\n",
       "   'x3': 22,\n",
       "   'y0': 177,\n",
       "   'y1': 177,\n",
       "   'y2': 189,\n",
       "   'y3': 189},\n",
       "  'text': '20000',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 11,\n",
       "  'polygon': {'x0': 46,\n",
       "   'x1': 55,\n",
       "   'x2': 55,\n",
       "   'x3': 46,\n",
       "   'y0': 200,\n",
       "   'y1': 200,\n",
       "   'y2': 211,\n",
       "   'y3': 211},\n",
       "  'text': '0',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 12,\n",
       "  'polygon': {'x0': 39,\n",
       "   'x1': 73,\n",
       "   'x2': 81,\n",
       "   'x3': 47,\n",
       "   'y0': 246,\n",
       "   'y1': 211,\n",
       "   'y2': 220,\n",
       "   'y3': 254},\n",
       "  'text': 'Sri Lanka',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 13,\n",
       "  'polygon': {'x0': 72,\n",
       "   'x1': 101,\n",
       "   'x2': 110,\n",
       "   'x3': 81,\n",
       "   'y0': 241,\n",
       "   'y1': 211,\n",
       "   'y2': 220,\n",
       "   'y3': 249},\n",
       "  'text': 'Sweden',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 14,\n",
       "  'polygon': {'x0': 88,\n",
       "   'x1': 130,\n",
       "   'x2': 138,\n",
       "   'x3': 97,\n",
       "   'y0': 253,\n",
       "   'y1': 212,\n",
       "   'y2': 220,\n",
       "   'y3': 261},\n",
       "  'text': 'Switzerland',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 15,\n",
       "  'polygon': {'x0': 139,\n",
       "   'x1': 159,\n",
       "   'x2': 168,\n",
       "   'x3': 148,\n",
       "   'y0': 230,\n",
       "   'y1': 212,\n",
       "   'y2': 222,\n",
       "   'y3': 240},\n",
       "  'text': 'Syria',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 16,\n",
       "  'polygon': {'x0': 160,\n",
       "   'x1': 187,\n",
       "   'x2': 195,\n",
       "   'x3': 168,\n",
       "   'y0': 239,\n",
       "   'y1': 212,\n",
       "   'y2': 220,\n",
       "   'y3': 247},\n",
       "  'text': 'Taiwan',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 17,\n",
       "  'polygon': {'x0': 180,\n",
       "   'x1': 215,\n",
       "   'x2': 224,\n",
       "   'x3': 190,\n",
       "   'y0': 246,\n",
       "   'y1': 212,\n",
       "   'y2': 222,\n",
       "   'y3': 256},\n",
       "  'text': 'Tajikistan',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 18,\n",
       "  'polygon': {'x0': 209,\n",
       "   'x1': 243,\n",
       "   'x2': 251,\n",
       "   'x3': 218,\n",
       "   'y0': 245,\n",
       "   'y1': 211,\n",
       "   'y2': 220,\n",
       "   'y3': 253},\n",
       "  'text': 'Tanzania',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 19,\n",
       "  'polygon': {'x0': 240,\n",
       "   'x1': 272,\n",
       "   'x2': 280,\n",
       "   'x3': 249,\n",
       "   'y0': 243,\n",
       "   'y1': 212,\n",
       "   'y2': 220,\n",
       "   'y3': 251},\n",
       "  'text': 'Thailand',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 20,\n",
       "  'polygon': {'x0': 260,\n",
       "   'x1': 300,\n",
       "   'x2': 308,\n",
       "   'x3': 269,\n",
       "   'y0': 251,\n",
       "   'y1': 212,\n",
       "   'y2': 220,\n",
       "   'y3': 259},\n",
       "  'text': 'Uzbekistan',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 21,\n",
       "  'polygon': {'x0': 290,\n",
       "   'x1': 328,\n",
       "   'x2': 336,\n",
       "   'x3': 298,\n",
       "   'y0': 249,\n",
       "   'y1': 212,\n",
       "   'y2': 221,\n",
       "   'y3': 258},\n",
       "  'text': 'Venezuela',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 22,\n",
       "  'polygon': {'x0': 326,\n",
       "   'x1': 359,\n",
       "   'x2': 366,\n",
       "   'x3': 334,\n",
       "   'y0': 241,\n",
       "   'y1': 213,\n",
       "   'y2': 222,\n",
       "   'y3': 250},\n",
       "  'text': 'Vietnam',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 23,\n",
       "  'polygon': {'x0': 363,\n",
       "   'x1': 385,\n",
       "   'x2': 393,\n",
       "   'x3': 371,\n",
       "   'y0': 234,\n",
       "   'y1': 211,\n",
       "   'y2': 220,\n",
       "   'y3': 242},\n",
       "  'text': 'World',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 24,\n",
       "  'polygon': {'x0': 387,\n",
       "   'x1': 413,\n",
       "   'x2': 421,\n",
       "   'x3': 395,\n",
       "   'y0': 238,\n",
       "   'y1': 211,\n",
       "   'y2': 220,\n",
       "   'y3': 246},\n",
       "  'text': 'Yemen',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 25,\n",
       "  'polygon': {'x0': 414,\n",
       "   'x1': 442,\n",
       "   'x2': 450,\n",
       "   'x3': 423,\n",
       "   'y0': 239,\n",
       "   'y1': 212,\n",
       "   'y2': 220,\n",
       "   'y3': 247},\n",
       "  'text': 'Zambia',\n",
       "  'role': 'tick_label'},\n",
       " {'id': 26,\n",
       "  'polygon': {'x0': 433,\n",
       "   'x1': 470,\n",
       "   'x2': 478,\n",
       "   'x3': 441,\n",
       "   'y0': 249,\n",
       "   'y1': 211,\n",
       "   'y2': 220,\n",
       "   'y3': 257},\n",
       "  'text': 'Zimbabwe',\n",
       "  'role': 'tick_label'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9af7725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ylab = \"\"\n",
    "for i in range(3, int((len(data['text'])-3)/2)):\n",
    "    ylab = ylab + data['text'][i]['text'] + \";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3b333d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'160000;140000;120000;100000;80000;60000;40000;20000;0;'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c87df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlab = \"\"\n",
    "for i in range(int((len(data['text'])-3)/2), len(data['text'])):\n",
    "    xlab = xlab + data['text'][i]['text'] + \";\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "38f2d1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sri Lanka;Sweden;Switzerland;Syria;Taiwan;Tajikistan;Tanzania;Thailand;Uzbekistan;Venezuela;Vietnam;World;Yemen;Zambia;Zimbabwe;'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf85be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "efnet_weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "efnet_model = torchvision.models.efficientnet_b0(weights = efnet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5915f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "efnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d47fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Train the neural network on the data using batches\n",
    "from torch import nn\n",
    "epochs = 100\n",
    "lrate = 0.1\n",
    "cost_fn = nn.NLLLoss()\n",
    "net = efnet_model\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lrate)\n",
    "track_cost = np.zeros(epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    cur_cost = 0.0\n",
    "    correct = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.reshape(inputs.size())\n",
    "        outputs = net(inputs)\n",
    "        #print(labels)\n",
    "        \n",
    "        cost = cost_fn(outputs.log_softmax(dim=1), labels)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        cur_cost += cost.item()\n",
    "        \n",
    "    track_cost[epoch] = cur_cost\n",
    "    print(f\"Epoch: {epoch} Cost: {cur_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec44d044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce66d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ede6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\images'\n",
    "json_path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\annotations'\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas import get_dummies\n",
    "\n",
    "bsize=256\n",
    "\n",
    "img_names = os.listdir(path)\n",
    "#img_name = path + '\\\\' + name\n",
    "#json_names = os.listdir(json_path)\n",
    "i=0\n",
    "#ADD TRAIN TEST SPLIT HERE TO IMG_NAMES\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(img_names, test_size=0.9, random_state=5)\n",
    "\n",
    "images = np.empty(shape = (bsize, 3, 256, 256))\n",
    "labels = np.chararray(bsize, itemsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.copy()\n",
    "train_X = train.copy()\n",
    "for i in range(len(train)):\n",
    "    train_X[i] = path + '\\\\' + img_names[i]\n",
    "    train_y[i] = json_path + '\\\\' + img_names[i]\n",
    "    train_y[i] = train_y[i].replace(train_y[i][len(train_y[i]) - 3:], 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50941fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f53c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index])\n",
    "        f = open(self.label_paths[index])\n",
    "        data = json.load(f)\n",
    "        t = data['chart-type']\n",
    "        #x\n",
    "        x = \"x,\"\n",
    "        for i in range(len(data['data-series'])):\n",
    "            x += str(data['data-series'][i]['x'])\n",
    "            x += \";\"\n",
    "        x=x[:-1] + ', ' + data['chart-type']\n",
    "        #y\n",
    "        y = \"y,\"\n",
    "        for i in range(len(data['data-series'])):\n",
    "            y += str(data['data-series'][i]['y'])\n",
    "            y += \";\"\n",
    "        y=y[:-1] + ', ' + data['chart-type']\n",
    "        label = x + \"\\n\" + y\n",
    "        #print(label)\n",
    "        f.close()\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            #label = self.transform(label)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# Define the transform to resize and normalize the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create a dataset from the image and label file paths\n",
    "dataset = MyDataset(train_X, train_y, transform=transform)\n",
    "\n",
    "# Create a dataloader to load the data in batches\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "efnet_weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "efnet_model = torchvision.models.efficientnet_b0(weights = efnet_weights)\n",
    "## Loop through each parameter and set `requires_grad` to false\n",
    "for param in efnet_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "## Replace the \"classifier\" layer with one for our application\n",
    "efnet_model.classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features=1280, out_features=4, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Train the neural network on the data using batches\n",
    "from torch import nn\n",
    "epochs = 100\n",
    "lrate = 0.1\n",
    "cost_fn = nn.NLLLoss()\n",
    "net = efnet_model\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lrate)\n",
    "track_cost = np.zeros(epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    cur_cost = 0.0\n",
    "    correct = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        #inputs = inputs.reshape(inputs.size())\n",
    "        outputs = net(inputs)\n",
    "        #print(labels)\n",
    "        labels = torch.tensor(labels)\n",
    "        \n",
    "        cost = cost_fn(outputs.log_softmax(dim=1), labels)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        cur_cost += cost.item()\n",
    "        \n",
    "    track_cost[epoch] = cur_cost\n",
    "    print(f\"Epoch: {epoch} Cost: {cur_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8abcfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD TEST CODE TO MAKE SURE IT WORKS\n",
    "test_y = test.copy()\n",
    "test_X = test.copy()\n",
    "i=0\n",
    "for i in range(len(test)):\n",
    "    test_X[i] = path + '\\\\' + img_names[i]\n",
    "    test_y[i] = json_path + '\\\\' + img_names[i]\n",
    "    test_y[i] = test_y[i].replace(test_y[i][len(test_y[i]) - 3:], 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1290fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(test_X, test_y, transform=transform)\n",
    "\n",
    "# Create a dataloader to load the data in batches\n",
    "batch_size = 256\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#LOOK AT HOW WELL THIS MODEL PERFORMS BY FIGURING OUT KAGGLE SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc67ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04fc6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf3e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\images'\n",
    "json_path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\annotations'\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas import get_dummies\n",
    "\n",
    "bsize=256\n",
    "\n",
    "img_names = os.listdir(path)\n",
    "#img_name = path + '\\\\' + name\n",
    "#json_names = os.listdir(json_path)\n",
    "i=0\n",
    "#ADD TRAIN TEST SPLIT HERE TO IMG_NAMES\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(img_names, test_size=0.9, random_state=5)\n",
    "\n",
    "images = np.empty(shape = (bsize, 3, 256, 256))\n",
    "labels = np.chararray(bsize, itemsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f51e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.copy()\n",
    "train_X = train.copy()\n",
    "for i in range(len(train)):\n",
    "    train_X[i] = path + '\\\\' + img_names[i]\n",
    "    train_y[i] = json_path + '\\\\' + img_names[i]\n",
    "    train_y[i] = train_y[i].replace(train_y[i][len(train_y[i]) - 3:], 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecfb3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5cf069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# define a custom dataset class for the new input format\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.x = torch.tensor([list(map(float, data['x'].split(';'))) for i in range(len(data))])\n",
    "        self.y = torch.tensor([list(map(float, data['y'].split(';'))) for i in range(len(data))])\n",
    "        self.graph_type = torch.tensor([self._map_graph_type(t) for t in data['type']])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.cat((self.x[idx], self.y[idx], self.graph_type[idx]), dim=0),)\n",
    "    \n",
    "    def _map_graph_type(self, t):\n",
    "        # define a dictionary mapping each graph type to a numerical value\n",
    "        graph_type_map = {'scatter': 0, 'line': 1, 'bar': 2, 'dot': 3}\n",
    "        return graph_type_map[t]\n",
    "\n",
    "# define the neural network architecture for predicting the x and y values\n",
    "class PointModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 16)\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# set up the training data loader using the custom dataset\n",
    "train_data = {'x': '1;2;3;4', 'y': '2;5;9;10', 'type': 'scatter'}\n",
    "train_dataset = GraphDataset(train_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1)\n",
    "\n",
    "# set up the neural network and training parameters\n",
    "epochs = 100\n",
    "lrate = 0.1\n",
    "cost_fn = nn.MSELoss()\n",
    "net = PointModel()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lrate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cddd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader, 0):\n",
    "    inputs, = data\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    # convert the output values back to their original scale\n",
    "    x_pred, y_pred = outputs[0].detach().numpy()\n",
    "    x_pred = (x_pred * (max(train_dataset.x.flatten()) - min(train_dataset.x.flatten()))) + min(train_dataset.x.flatten())\n",
    "    y_pred = (y_pred * (max(train_dataset.y.flatten()) - min(train_dataset.y.flatten()))) + min(train_dataset.y.flatten())\n",
    "    \n",
    "    # calculate the loss and update the neural network parameters\n",
    "    x, y, graph_type = inputs.detach().numpy()\n",
    "    x_true, y_true = x[:4], y[:4]\n",
    "    loss = cost_fn(outputs, torch.tensor([x_true, y_true]).T)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    cur_cost += loss.item()\n",
    "    \n",
    "track_cost[epoch] = cur_cost\n",
    "print(f\"Epoch: {epoch} Cost: {cur_cost}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c937787b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50db54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5eb05e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45094f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa977ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2075ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "#EXTRACT INFO ABOUT SCATTER PLOTS\n",
    "#EXTEND A PRETRAINED CAPTIONING MODEL TO CAPTION THOSE PLOTS\n",
    "#DO ONE MODEL FOR EACH TYPE OF GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0686d464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
