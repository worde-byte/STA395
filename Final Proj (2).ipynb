{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "my_img = io.imread(r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\images\\ffba62c94141.jpg')\n",
    "io.imshow(my_img)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd0f235",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\images'\n",
    "json_path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\annotations'\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "bsize=256\n",
    "\n",
    "img_names = os.listdir(path)\n",
    "#json_names = os.listdir(json_path)\n",
    "i=0\n",
    "#ADD TRAIN TEST SPLIT HERE TO IMG_NAMES\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(img_names, test_size=0.1, random_state=5)\n",
    "\n",
    "images = np.empty(shape = (bsize, 3, 256, 256))\n",
    "labels = np.chararray(bsize, itemsize=20)\n",
    "for idx, name in enumerate(img_names):\n",
    "    if (i==bsize):\n",
    "        break\n",
    "    img_name = path + '\\\\' + name\n",
    "    json_name = json_path + '\\\\' + name\n",
    "    json_name = json_name.replace(json_name[len(json_name) - 3:], 'json')\n",
    "    # Use you favourite library to load the image\n",
    "    image = plt.imread(img_name)\n",
    "    image = image.copy()\n",
    "    image = torch.from_numpy(image)\n",
    "    image = torch.unsqueeze(image, dim=0)\n",
    "    image = torch.movedim(image, source=3, destination=1)\n",
    "    image = functional.interpolate(image, size = (256,256))\n",
    "    \n",
    "    f = open(json_name)\n",
    "    data = json.load(f)\n",
    "    t = data['chart-type']\n",
    "    images[idx] = image\n",
    "    labels[idx] = t\n",
    "    f.close()\n",
    "    \n",
    "    #image_resized = functional.interpolate(image, size = (128,128))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d79e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc9b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_img=images[45]\n",
    "io.imshow(my_img)\n",
    "io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce7bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "efnet_weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "efnet_model = torchvision.models.efficientnet_b0(weights = efnet_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3d4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through each parameter and set `requires_grad` to false\n",
    "for param in efnet_model.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace the \"classifier\" layer with one for our application\n",
    "efnet_model.classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features=1280, out_features=4, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4619c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas import get_dummies\n",
    "\n",
    "train_y=labels\n",
    "train_X=images\n",
    "\n",
    "encode_list = [b'vertical_bar',b'scatter',b'dot',b'line']\n",
    "# Create an instance of the OneHotEncoder class and fit it on the data\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "encoder.fit(train_y.reshape(-1, 1))\n",
    "\n",
    "# Transform the data using the fitted encoder\n",
    "encoded_data = encoder.transform(train_y.reshape(-1, 1))\n",
    "\n",
    "# Map the encoded data to the desired format\n",
    "train_y = [encoder.categories_[0].tolist().index(category) for category in encoder.inverse_transform(encoded_data).flatten()]\n",
    "\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035ce064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "y_tensor = torch.tensor(train_y)\n",
    "\n",
    "### Convert to numpy array then reshape to 900 by 28 by 28\n",
    "mnist_unflattened = train_X\n",
    "mnist_unflattened = mnist_unflattened.reshape(256, 3, 256, 256)\n",
    "\n",
    "## Convert to tensor\n",
    "mnist_tensor = torch.from_numpy(mnist_unflattened)\n",
    "mnist_tensor =  torch.unsqueeze(mnist_tensor, dim=1)\n",
    "\n",
    "## Transform to proper input shape\n",
    "new_mnist_tensors = mnist_tensor.expand(-1, -1, -1, -1, -1)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(new_mnist_tensors.type(torch.FloatTensor), y_tensor.type(torch.LongTensor)), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd549ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparms\n",
    "epochs = 100\n",
    "lrate = 0.1\n",
    "\n",
    "## Cost Function\n",
    "from torch import nn\n",
    "cost_fn = nn.NLLLoss()\n",
    "\n",
    "## Network model\n",
    "torch.manual_seed(7) # For reproduction purposes (should be minor since only the last layers are randomly intialized)\n",
    "net = efnet_model\n",
    "\n",
    "## Optimizer (using ADAM, a more flexible algorithm than SGD this time)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lrate)\n",
    "\n",
    "## Initial values for cost tracking\n",
    "track_cost = np.zeros(epochs)\n",
    "cur_cost = 0.0\n",
    "\n",
    "## Loop through the data\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    cur_cost = 0.0\n",
    "    correct = 0.0\n",
    "    \n",
    "    ## train_loader is iterable and numbers knows the batch\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        ## The input tensor and labels tensor for the current batch\n",
    "        inputs, labels = data\n",
    "        ## Clear the gradient from the previous batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## Provide the input tensor into the network to get outputs\n",
    "        inputs = inputs.reshape((32, 3, 256, 256))\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        ## Calculate the cost for the current batch\n",
    "        cost = cost_fn(outputs.log_softmax(dim=1), labels)\n",
    "        \n",
    "        ## Calculate the gradient\n",
    "        cost.backward()\n",
    "        \n",
    "        ## Update the model parameters using the gradient\n",
    "        optimizer.step()\n",
    "        \n",
    "        ## Track the current cost (accumulating across batches)\n",
    "        cur_cost += cost.item()\n",
    "    \n",
    "    ## Store the accumulated cost at each epoch\n",
    "    track_cost[epoch] = cur_cost\n",
    "    print(f\"Epoch: {epoch} Cost: {cur_cost}\") ## Uncomment this if you want printed updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25777f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d4ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169dd465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb958b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd043056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05682f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd46c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e49c070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\images'\n",
    "json_path = r'C:\\Users\\16032\\Downloads\\benetech-making-graphs-accessible\\train\\annotations'\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas import get_dummies\n",
    "\n",
    "bsize=256\n",
    "\n",
    "img_names = os.listdir(path)\n",
    "#img_name = path + '\\\\' + name\n",
    "#json_names = os.listdir(json_path)\n",
    "i=0\n",
    "#ADD TRAIN TEST SPLIT HERE TO IMG_NAMES\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(img_names, test_size=0.1, random_state=5)\n",
    "\n",
    "images = np.empty(shape = (bsize, 3, 256, 256))\n",
    "labels = np.chararray(bsize, itemsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c93893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.copy()\n",
    "train_X = train.copy()\n",
    "for i in range(len(train)):\n",
    "    train_X[i] = path + '\\\\' + img_names[i]\n",
    "    train_y[i] = json_path + '\\\\' + img_names[i]\n",
    "    train_y[i] = train_y[i].replace(train_y[i][len(train_y[i]) - 3:], 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0552a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c24d746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc2343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index])\n",
    "        f = open(self.label_paths[index])\n",
    "        data = json.load(f)\n",
    "        t = data['chart-type']\n",
    "        #print(t)\n",
    "        if (t=='scatter'):\n",
    "            label = 0\n",
    "        elif (t=='vertical_bar'):\n",
    "            label = 1\n",
    "        elif (t=='dot'):\n",
    "            label = 2\n",
    "        else:\n",
    "            label = 3\n",
    "        f.close()\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            #label = self.transform(label)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# Define the transform to resize and normalize the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Create a dataset from the image and label file paths\n",
    "dataset = MyDataset(train_X, train_y, transform=transform)\n",
    "\n",
    "# Create a dataloader to load the data in batches\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c3f05b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "efnet_weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "efnet_model = torchvision.models.efficientnet_b0(weights = efnet_weights)\n",
    "## Loop through each parameter and set `requires_grad` to false\n",
    "for param in efnet_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "## Replace the \"classifier\" layer with one for our application\n",
    "efnet_model.classifier = torch.nn.Sequential( \n",
    "    torch.nn.Linear(in_features=1280, out_features=4, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efb7480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Cost: 43.08404497546144\n",
      "Epoch: 1 Cost: 16.833578320409288\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Train the neural network on the data using batches\n",
    "from torch import nn\n",
    "epochs = 100\n",
    "lrate = 0.1\n",
    "cost_fn = nn.NLLLoss()\n",
    "net = efnet_model\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lrate)\n",
    "track_cost = np.zeros(epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    cur_cost = 0.0\n",
    "    correct = 0.0\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.reshape(inputs.size())\n",
    "        outputs = net(inputs)\n",
    "        #print(labels)\n",
    "        \n",
    "        cost = cost_fn(outputs.log_softmax(dim=1), labels)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        cur_cost += cost.item()\n",
    "        \n",
    "    track_cost[epoch] = cur_cost\n",
    "    print(f\"Epoch: {epoch} Cost: {cur_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8fc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e49946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058242ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
